{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Sessions "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: \n",
    "\n",
    "Extract the session data, transform it into a dataframe that can be compared to and used with other part of the app "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd \n",
    "from xml.etree import ElementTree\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config variables\n",
    "\n",
    "ROOT_DIR = Path('~/Projects/Data/ccrsApp/backend')\n",
    "DATA_DIR = ROOT_DIR/'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcitons \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def is_cjk(char):\n",
    "    char = ord(char)\n",
    "    cjk_ranges = [\n",
    "    (0x4E00,  0x62FF),\n",
    "    (0x6300,  0x77FF),\n",
    "    (0x7800,  0x8CFF),\n",
    "    (0x8D00,  0x9FCC),\n",
    "    (0x3400,  0x4DB5),\n",
    "    (0x20000, 0x215FF),\n",
    "    (0x21600, 0x230FF),\n",
    "    (0x23100, 0x245FF),\n",
    "    (0x24600, 0x260FF),\n",
    "    (0x26100, 0x275FF),\n",
    "    (0x27600, 0x290FF),\n",
    "    (0x29100, 0x2A6DF),\n",
    "    (0x2A700, 0x2B734),\n",
    "    (0x2B740, 0x2B81D),\n",
    "    (0x2B820, 0x2CEAF),\n",
    "    (0x2CEB0, 0x2EBEF),\n",
    "    (0x2F800, 0x2FA1F), ]\n",
    "\n",
    "    \n",
    "    \n",
    "    for bottom, top in cjk_ranges:\n",
    "        if char >= bottom and char <= top:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Adds new words\n",
    "def new_vocab_df_generator(elem):\n",
    "    \"\"\"_summary_\n",
    "    \n",
    "    Takes in an xml element, returns a dataframe of the chinese characters in each element\n",
    "    along with the date\n",
    "    \n",
    "    Added\n",
    "    \n",
    "    Args:\n",
    "        elem (_type_): _description_\n",
    "        xml element, expected to be in the opml format from workflowy\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    #vocab_df = pd.DataFrame({}, columns=['Characters', 'Date'])\n",
    "\n",
    "    vocabFromCat = []\n",
    "    catName = elem.attrib['text']\n",
    "    for lessonNotes in elem.iter():\n",
    "        # print(elementsDateAdded[i])\n",
    "        \n",
    "        for note in lessonNotes:\n",
    "            #print(note)\n",
    "            noteText = note.attrib['text']\n",
    "\n",
    "            chineseCharacters = ''\n",
    "\n",
    "            for char in noteText:\n",
    "                if is_cjk(char):\n",
    "                    chineseCharacters += char\n",
    "\n",
    "            vocabFromCat.append(chineseCharacters)\n",
    "\n",
    "        # Generates a column of same shape as vocab\n",
    "        #dateColumn = [elementsDateAdded[i]] * len(vocabFromLesson)\n",
    "        \n",
    "        #lessonDictionary = dict(zipvocabFromLesson)\n",
    "        catCol = [catName] * len(vocabFromCat)\n",
    "        #catDictionary = dict(zip(vocabFromCat,catCol))\n",
    "        tmp_df = pd.DataFrame({'Characters':vocabFromCat,\n",
    "                               'Cat':catCol},dtype='object')\n",
    "        print(tmp_df.shape)\n",
    "        return tmp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = '../data/tutor_session_notes.opml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fileName, 'rt') as f:\n",
    "        tree = ElementTree.parse(f)\n",
    "\n",
    "notesRoot = tree.getroot()\n",
    "\n",
    "notesBody = notesRoot.find('body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_child_element(child_elem_text,parent_elem):\n",
    "    childElement = None\n",
    "\n",
    "    for elem in parent_elem:\n",
    "        #print(elem.attrib['text'] )\n",
    "\n",
    "        if elem.attrib['text']  is not None and elem.attrib['text'].strip() == child_elem_text:\n",
    "            childElement  = elem\n",
    "            break\n",
    "    \n",
    "    if childElement is not None:\n",
    "        return childElement\n",
    "    else: \n",
    "        print('No Elem Found')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_child =  find_child_element('<span class=\"colored bc-pink\">Knowledge</span>',notesBody)\n",
    "\n",
    "next_child = find_child_element('Active Subjects',next_child)\n",
    "next_child = find_child_element('Chinese #huayu', next_child)\n",
    "next_child =  find_child_element('好好学习，天天上上',next_child)\n",
    "tutor_session_notes = find_child_element('Tutor Session Notes',next_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Looks for element text which matches internal \n",
    "# workflowy pattern in opml \n",
    "timePattern = re.compile('time startYear')\n",
    "\n",
    "# Creating list of elements\n",
    "# Which contain lesson notes \n",
    "\n",
    "session_dict = {}\n",
    "\n",
    "\n",
    "# Checks for elements which contain dates\n",
    "# Which will contain sub elements with vocab\n",
    "# Appends them to a list, along with the dates\n",
    "# From before\n",
    "\n",
    "for outline in tutor_session_notes.iter():\n",
    "\n",
    "    text = outline.attrib['text']\n",
    "    #Extracts the Date \n",
    "    # finds new nodes\n",
    "    \n",
    "    hasTime = re.search(timePattern,text)\n",
    "    \n",
    "    if hasTime:\n",
    "        #Extracting datetime info\n",
    "        time = text.split()\n",
    "        year = time[1].split('\\\"')[1]\n",
    "        month = time[2].split('\\\"')[1]\n",
    "        day = time[3].split('\\\"')[1]\n",
    "        dateAdded = year+' '+month +' '+day\n",
    "        #print(dateAdded)\n",
    "        \n",
    "        session_dict[dateAdded] = outline\n",
    "\n",
    "    else:\n",
    "        continue \n",
    "\n",
    "#print(elementsByDate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'...'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('...','... ...')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 're' has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jentlejames/Projects/Data/ccrsApp/backend/nb/workflowy_extract_notes.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jentlejames/Projects/Data/ccrsApp/backend/nb/workflowy_extract_notes.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m re\u001b[39m.\u001b[39;49mfind\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 're' has no attribute 'find'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSession = session_dict['2023 4 5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '…' (U+2026) (4117168034.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [49]\u001b[0;36m\u001b[0m\n\u001b[0;31m    re…search\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '…' (U+2026)\n"
     ]
    }
   ],
   "source": [
    "re…search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg\n",
    "\n",
    "def pos_tag(text):\n",
    "    words = pseg.cut(text)\n",
    "    tags = []\n",
    "    for word, tag in words:\n",
    "        tags.append((word, tag))\n",
    "    return tags\n",
    "\n",
    "def count_parts_of_speech(text):\n",
    "    tag_counts = {}\n",
    "    tags = pos_tag(text)\n",
    "    for word, tag in tags:\n",
    "        if tag in tag_counts:\n",
    "            tag_counts[tag] += 1\n",
    "        else:\n",
    "            tag_counts[tag] = 1\n",
    "    return len(tag_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jentlejames/Projects/Data/ccrsApp/backend/nb/workflowy_extract_notes.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jentlejames/Projects/Data/ccrsApp/backend/nb/workflowy_extract_notes.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mlen\u001b[39;49m(\u001b[39mNone\u001b[39;49;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "len(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(session_dict)\n",
    "import unicodedata\n",
    "\n",
    "#is_example_grammar\n",
    "\n",
    "lessonColumns = ['characters','full_text']\n",
    "df_lesson = pd.DataFrame({},lessonColumns)\n",
    "\n",
    "# To concat at the end\n",
    "session_df_list = []\n",
    "\n",
    "for session_date, session_notes in session_dict.items():\n",
    "    chineseCharactersList = []\n",
    "    lesson_notes_text_list = []\n",
    "    # Extracts Chinese Charcters\n",
    "    for noteIdx, lesson_note in enumerate(session_notes.iter()):\n",
    "        # skips first note that contains date information\n",
    "        if (noteIdx == 0):\n",
    "            continue\n",
    "        \n",
    "        lesson_note.attrib['text'] = unicodedata.normalize('NFC', lesson_note.attrib['text'])\n",
    "\n",
    "        chineseCharacters = ''\n",
    "        for char in lesson_note.attrib['text']:\n",
    "            if is_cjk(char):\n",
    "                chineseCharacters += char\n",
    "        \n",
    "        # adding to a list for later, none to keep \n",
    "        if len(chineseCharacters) > 0: \n",
    "            chineseCharactersList.append(chineseCharacters)\n",
    "        else:\n",
    "            chineseCharactersList.append('')\n",
    "        lesson_notes_text_list.append(lesson_note.attrib['text'])\n",
    "    \n",
    "    assert len(chineseCharactersList) == len(lesson_notes_text_list)\n",
    "\n",
    "    # determine the type of note\n",
    "\n",
    "    noteTypeList = []\n",
    "    \n",
    "    for noteIdx, noteText in enumerate(lesson_notes_text_list):\n",
    "\n",
    "        note_chinese = chineseCharactersList[noteIdx]\n",
    "\n",
    "        if len(note_chinese) == 0:\n",
    "            noteTypeList.append('English')\n",
    "        \n",
    "        elif len(note_chinese) < 5:\n",
    "            noteTypeList.append('Vocab')\n",
    "        \n",
    "        elif len(re.findall('\\.\\.|…',noteText.replace(' ',''))) > 2 :\n",
    "            noteTypeList.append('Grammar')\n",
    "        \n",
    "        elif len(note_chinese) > 4:\n",
    "            unique_parts_of_speech =  count_parts_of_speech(note_chinese)\n",
    "            if unique_parts_of_speech > 3:\n",
    "                noteTypeList.append('Sentence')\n",
    "            else:\n",
    "                noteTypeList.append('Phrase')\n",
    "        else:\n",
    "            noteTypeList.append('?')\n",
    "        \n",
    "    assert len(noteTypeList) == len(chineseCharactersList)\n",
    "    \n",
    "    df_indv_session =  pd.DataFrame({'hanzi': chineseCharactersList,\n",
    "                                    'full_text': lesson_notes_text_list,\n",
    "                                    'note_type': noteTypeList,\n",
    "                                    'date' : session_date })\n",
    "    \n",
    "    session_df_list.append(df_indv_session)\n",
    "\n",
    "df_lesson_notes = pd.concat(session_df_list)\n",
    "df_lesson_notes = df_lesson_notes[df_lesson_notes.full_text.str.len() > 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lesson_notes.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lesson_notes.to_csv('../data/lesson_notes_2023_04_12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>标签</th>\n",
    "<th>含义</th>\n",
    "<th>标签</th>\n",
    "<th>含义</th>\n",
    "<th>标签</th>\n",
    "<th>含义</th>\n",
    "<th>标签</th>\n",
    "<th>含义</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>n</td>\n",
    "<td>普通名词</td>\n",
    "<td>f</td>\n",
    "<td>方位名词</td>\n",
    "<td>s</td>\n",
    "<td>处所名词</td>\n",
    "<td>t</td>\n",
    "<td>时间</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>nr</td>\n",
    "<td>人名</td>\n",
    "<td>ns</td>\n",
    "<td>地名</td>\n",
    "<td>nt</td>\n",
    "<td>机构名</td>\n",
    "<td>nw</td>\n",
    "<td>作品名</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>nz</td>\n",
    "<td>其他专名</td>\n",
    "<td>v</td>\n",
    "<td>普通动词</td>\n",
    "<td>vd</td>\n",
    "<td>动副词</td>\n",
    "<td>vn</td>\n",
    "<td>名动词</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>a</td>\n",
    "<td>形容词</td>\n",
    "<td>ad</td>\n",
    "<td>副形词</td>\n",
    "<td>an</td>\n",
    "<td>名形词</td>\n",
    "<td>d</td>\n",
    "<td>副词</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>m</td>\n",
    "<td>数量词</td>\n",
    "<td>q</td>\n",
    "<td>量词</td>\n",
    "<td>r</td>\n",
    "<td>代词</td>\n",
    "<td>p</td>\n",
    "<td>介词</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>c</td>\n",
    "<td>连词</td>\n",
    "<td>u</td>\n",
    "<td>助词</td>\n",
    "<td>xc</td>\n",
    "<td>其他虚词</td>\n",
    "<td>w</td>\n",
    "<td>标点符号</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>PER</td>\n",
    "<td>人名</td>\n",
    "<td>LOC</td>\n",
    "<td>地名</td>\n",
    "<td>ORG</td>\n",
    "<td>机构名</td>\n",
    "<td>TIME</td>\n",
    "<td>时间</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds new words\n",
    "def new_vocab_df_generator(elem):\n",
    "    \"\"\"_summary_\n",
    "    \n",
    "    Takes in an xml element, returns a dataframe of the chinese characters in each element\n",
    "    along with the date\n",
    "    \n",
    "    Added\n",
    "    \n",
    "    Args:\n",
    "        elem (_type_): _description_\n",
    "        xml element, expected to be in the opml format from workflowy\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_df = pd.DataFrame({}, columns=['Characters', 'Date'])\n",
    "\n",
    "    for i, lessonNotes in new_sessions.iter:\n",
    "\n",
    "        vocabFromLesson = []\n",
    "\n",
    "        # print(elementsDateAdded[i])\n",
    "        for note in lessonNotes:\n",
    "            noteText = note.attrib['text']\n",
    "\n",
    "            chineseCharacters = ''\n",
    "\n",
    "            for char in noteText:\n",
    "                if is_cjk(char):\n",
    "                    chineseCharacters += char\n",
    "\n",
    "            vocabFromLesson.append(chineseCharacters)\n",
    "\n",
    "        # Generates a column of same shape as vocab\n",
    "        dateColumn = [elementsDateAdded[i]] * len(vocabFromLesson)\n",
    "        lessonDictionary = {'Characters': vocabFromLesson,\n",
    "                            'Date': dateColumn}\n",
    "        # dict(zip(vocabFromLesson,dateColumn))\n",
    "\n",
    "        df_dictionary = pd.DataFrame(lessonDictionary, columns=['Characters', 'Date'])\n",
    "\n",
    "        return df_dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChineseAutomation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
