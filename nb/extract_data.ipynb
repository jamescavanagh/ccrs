{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the Data for this app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install stopwordsiso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# NLP\n",
    "import jieba\n",
    "import stopwordsiso #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('/home/jentlejames/Projects/Data/Chinese Automation/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jentlejames/Projects/Data/Chinese Automation/data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../db/ccrs.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.read_csv(DATA_DIR/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hanzi = pd.read_csv(DATA_DIR/'extracted'/'uniqueCharacters.csv',index_col=0)\n",
    "df_hanzi['hanzi_index'] = df_hanzi.index + 1_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hanzi</th>\n",
       "      <th>raw_frequency</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>definition</th>\n",
       "      <th>stroke_count</th>\n",
       "      <th>hanzi_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>豪</td>\n",
       "      <td>94.646005</td>\n",
       "      <td>háo</td>\n",
       "      <td>grand/heroic</td>\n",
       "      <td>14</td>\n",
       "      <td>1001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>穷</td>\n",
       "      <td>93.289896</td>\n",
       "      <td>qióng</td>\n",
       "      <td>exhausted/poor</td>\n",
       "      <td>7</td>\n",
       "      <td>1001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6928</th>\n",
       "      <td>餬</td>\n",
       "      <td>99.994711</td>\n",
       "      <td>hú</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>1006928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hanzi  raw_frequency pinyin      definition stroke_count  hanzi_index\n",
       "1512     豪      94.646005    háo    grand/heroic           14      1001512\n",
       "1342     穷      93.289896  qióng  exhausted/poor            7      1001342\n",
       "6928     餬      99.994711     hú             NaN           17      1006928"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter by column\n",
    "hanziColumns = ['char','cumulativeRawFrequency','kMandarin','English','kTotalStrokes','hanzi_index']\n",
    "df_hanzi = df_hanzi[hanziColumns].copy()\n",
    "\n",
    "# Rename for sql column standard\n",
    "df_hanzi.columns = ['hanzi','raw_frequency','pinyin','definition','stroke_count','hanzi_index']\n",
    "df_hanzi.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9933"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hanzi.to_sql('hanzi_info',conn,if_exists='replace',index=df_hanzi['hanzi_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hanzi</th>\n",
       "      <th>raw_frequency</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>definition</th>\n",
       "      <th>stroke_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hanzi_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000408</th>\n",
       "      <td>价</td>\n",
       "      <td>71.490523</td>\n",
       "      <td>jià</td>\n",
       "      <td>price/value/valence (on an atom), great/good/m...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002056</th>\n",
       "      <td>俘</td>\n",
       "      <td>97.328262</td>\n",
       "      <td>fú</td>\n",
       "      <td>prisoner of war</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001274</th>\n",
       "      <td>播</td>\n",
       "      <td>92.644179</td>\n",
       "      <td>bō</td>\n",
       "      <td>sow/scatter/spread/broadcast</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hanzi  raw_frequency pinyin  \\\n",
       "hanzi_index                               \n",
       "1000408         价      71.490523    jià   \n",
       "1002056         俘      97.328262     fú   \n",
       "1001274         播      92.644179     bō   \n",
       "\n",
       "                                                    definition stroke_count  \n",
       "hanzi_index                                                                  \n",
       "1000408      price/value/valence (on an atom), great/good/m...            6  \n",
       "1002056                                        prisoner of war            9  \n",
       "1001274                           sow/scatter/spread/broadcast           15  "
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hanzi = pd.read_sql('SELECT * FROM hanzi_info', conn, index_col='hanzi_index')\n",
    "test_hanzi.sample(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radicals = pd.read_csv(DATA_DIR/'extracted'/'Radicals.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective 2: Meaning and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>a, an</td>\n",
       "      <td>alone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>number one</td>\n",
       "      <td>line</td>\n",
       "      <td>Kangxi radical 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>line</td>\n",
       "      <td>Kangxi radical 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>second</td>\n",
       "      <td>2nd heavenly stem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hook</td>\n",
       "      <td>Kangxi radical 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                   1                  2    3    4\n",
       "0         one               a, an              alone  NaN  NaN\n",
       "1  number one                line   Kangxi radical 2  NaN  NaN\n",
       "2        line    Kangxi radical 4                NaN  NaN  NaN\n",
       "3      second   2nd heavenly stem                NaN  NaN  NaN\n",
       "4        hook    Kangxi radical 6                NaN  NaN  NaN"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# English Category Clean up \n",
    "# Remove whitespace formatting\n",
    "df_radicals['english']  = df_radicals.english.str.replace('\\xad','')\n",
    "\n",
    "# Cleaning up the list of definitions \n",
    "\n",
    "# Needs to deal with the nested list, expanding it out into a table\n",
    "df_radicals['Meaning'] = df_radicals['kDefinition'].str.split(';')\n",
    "df_meaning = df_radicals['Meaning'].apply(pd.Series).copy()\n",
    "df_meaning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the extra information about Kangxi Radicals\n",
    "for i in range(5):\n",
    "    df_meaning[i] = np.where(df_meaning[i].str.contains('Kangxi'),np.NaN,df_meaning[i])\n",
    "    df_meaning[i] = df_meaning[i].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>radical</th>\n",
       "      <th>variants</th>\n",
       "      <th>simplifiedradical</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>english</th>\n",
       "      <th>strokecount</th>\n",
       "      <th>char</th>\n",
       "      <th>ucn</th>\n",
       "      <th>kDefinition</th>\n",
       "      <th>Meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yi1</td>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>一</td>\n",
       "      <td>U+4E00</td>\n",
       "      <td>one; a, an; alone</td>\n",
       "      <td>[one,  a, an,  alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>丨</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gun3</td>\n",
       "      <td>line</td>\n",
       "      <td>1</td>\n",
       "      <td>丨</td>\n",
       "      <td>U+4E28</td>\n",
       "      <td>number one; line; Kangxi radical 2</td>\n",
       "      <td>[number one,  line,  Kangxi radical 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>丿</td>\n",
       "      <td>乀 (fu2), 乁(yi2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pie3</td>\n",
       "      <td>slash</td>\n",
       "      <td>1</td>\n",
       "      <td>丿</td>\n",
       "      <td>U+4E3F</td>\n",
       "      <td>line; Kangxi radical 4</td>\n",
       "      <td>[line,  Kangxi radical 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>乙</td>\n",
       "      <td>乚 (yin3), 乛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yi4</td>\n",
       "      <td>second</td>\n",
       "      <td>1</td>\n",
       "      <td>乙</td>\n",
       "      <td>U+4E59</td>\n",
       "      <td>second; 2nd heavenly stem</td>\n",
       "      <td>[second,  2nd heavenly stem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>亅</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jue2</td>\n",
       "      <td>hook</td>\n",
       "      <td>1</td>\n",
       "      <td>亅</td>\n",
       "      <td>U+4E85</td>\n",
       "      <td>hook; Kangxi radical 6</td>\n",
       "      <td>[hook,  Kangxi radical 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number radical         variants simplifiedradical pinyin english  \\\n",
       "0       1       一              NaN               NaN    yi1     one   \n",
       "1       2       丨              NaN               NaN   gun3    line   \n",
       "2       4       丿  乀 (fu2), 乁(yi2)               NaN   pie3   slash   \n",
       "3       5       乙      乚 (yin3), 乛               NaN    yi4  second   \n",
       "4       6       亅              NaN               NaN   jue2    hook   \n",
       "\n",
       "   strokecount char     ucn                         kDefinition  \\\n",
       "0            1    一  U+4E00                   one; a, an; alone   \n",
       "1            1    丨  U+4E28  number one; line; Kangxi radical 2   \n",
       "2            1    丿  U+4E3F              line; Kangxi radical 4   \n",
       "3            1    乙  U+4E59           second; 2nd heavenly stem   \n",
       "4            1    亅  U+4E85              hook; Kangxi radical 6   \n",
       "\n",
       "                                  Meaning  \n",
       "0                   [one,  a, an,  alone]  \n",
       "1  [number one,  line,  Kangxi radical 2]  \n",
       "2               [line,  Kangxi radical 4]  \n",
       "3            [second,  2nd heavenly stem]  \n",
       "4               [hook,  Kangxi radical 6]  "
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_radicals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line is to unpack the definitions even further, with the goal of\n",
    "# unpacking the nested lists inside of the nested lists\n",
    "\n",
    "# Populating an empty array\n",
    "df_meaning['idx'] = np.NaN\n",
    "\n",
    "# Recurses through each column, adding where it iis found  \n",
    "for i in range(5):\n",
    "    df_meaning['idx'] = np.where(df_radicals['english'] == df_meaning[i],i,df_meaning['idx'])\n",
    "\n",
    "\n",
    "# Checking for redundant definitions\n",
    "secondaryCheckIdx = df_meaning['idx'].isnull()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meaning['english'] = df_radicals['english']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpacking Level 2 nested list of definitions, checking for matches\n",
    "#df_meaning[df_meaning[4].str.contains(',') == True]\n",
    "\n",
    "\n",
    "commaMeanings0 = df_meaning[secondaryCheckIdx][0].str.split(', | or ').apply(pd.Series)\n",
    "#print(commaMeanings0.shape[1])\n",
    "commaMeanings1 = df_meaning[secondaryCheckIdx][1].str.split(', | or ').apply(pd.Series)\n",
    "#print(commaMeanings1.shape[0])\n",
    "# Merging two nested lists together in order to check for matching words that indicate redudant information \n",
    "commaMeanings = pd.merge(commaMeanings0,commaMeanings1,how='outer',on=commaMeanings0.index).drop('key_0',axis=1)\n",
    "\n",
    "# Makes possible to iterate through each\n",
    "commaMeanings.columns = range(commaMeanings.shape[1])\n",
    "\n",
    "commaMeanings['single_word_def_is_redundant'] = np.NaN\n",
    "commaMeanings['english'] = df_meaning[secondaryCheckIdx].english.reset_index(drop=True)\n",
    "\n",
    "for i in range(commaMeanings.shape[1] -2 ): # -2 for index column and english column\n",
    "    commaMeanings['single_word_def_is_redundant'] = np.where(commaMeanings['english'] == commaMeanings[i], i, commaMeanings['single_word_def_is_redundant'])\n",
    "\n",
    "commaMeanings['merge_idx'] =  df_meaning[secondaryCheckIdx].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 8)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meaning = pd.merge(df_meaning,commaMeanings[['merge_idx','single_word_def_is_redundant']],how='left',left_on=df_meaning.index,right_on='merge_idx').drop('merge_idx',axis=1)\n",
    "df_meaning.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meaning['english'] = np.where(df_meaning['single_word_def_is_redundant'].isnull() & df_meaning['idx'].isnull(),df_meaning['english'],np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meaning = df_meaning[['english',0,1,2,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>one</td>\n",
       "      <td>a, an</td>\n",
       "      <td>alone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>number one</td>\n",
       "      <td>line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>slash</td>\n",
       "      <td>line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>second</td>\n",
       "      <td>2nd heavenly stem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>hook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>NaN</td>\n",
       "      <td>even, uniform, of equal length</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>tooth</td>\n",
       "      <td>teeth</td>\n",
       "      <td>gears, cogs</td>\n",
       "      <td>age</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>NaN</td>\n",
       "      <td>dragon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>NaN</td>\n",
       "      <td>turtle or tortoise</td>\n",
       "      <td>cuckold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>NaN</td>\n",
       "      <td>flute</td>\n",
       "      <td>pipe, ancient measure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    english                               0                      1      2  \\\n",
       "0       NaN                             one                  a, an  alone   \n",
       "1       NaN                      number one                   line    NaN   \n",
       "2     slash                            line                    NaN    NaN   \n",
       "3       NaN                          second      2nd heavenly stem    NaN   \n",
       "4       NaN                            hook                    NaN    NaN   \n",
       "..      ...                             ...                    ...    ...   \n",
       "209     NaN  even, uniform, of equal length                    NaN    NaN   \n",
       "210   tooth                           teeth            gears, cogs    age   \n",
       "211     NaN                          dragon                    NaN    NaN   \n",
       "212     NaN              turtle or tortoise                cuckold    NaN   \n",
       "213     NaN                           flute  pipe, ancient measure    NaN   \n",
       "\n",
       "       3    4  \n",
       "0    NaN  NaN  \n",
       "1    NaN  NaN  \n",
       "2    NaN  NaN  \n",
       "3    NaN  NaN  \n",
       "4    NaN  NaN  \n",
       "..   ...  ...  \n",
       "209  NaN  NaN  \n",
       "210  NaN  NaN  \n",
       "211  NaN  NaN  \n",
       "212  NaN  NaN  \n",
       "213  NaN  NaN  \n",
       "\n",
       "[214 rows x 6 columns]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radicals['Meaning'] = df_meaning.apply(lambda x: ', '.join(x.dropna()), axis=1)\n",
    "df_radicals['Meaning'] = '[' + df_radicals['Meaning'] + ']'\n",
    "df_radicals.drop(['kDefinition','english'],axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "radical_variants =  df_radicals['variants']#.str.split(',').dropna()\n",
    "radical_variants =  radical_variants.str.replace('\\([a-z1-4]*\\)','',regex=True).dropna()\n",
    "radical_variants.str.replace('\\s?,\\s?', ',',regex=True)\n",
    "radical_variants_unique =  radical_variants.str.split(',').apply(pd.Series).copy()\n",
    "\n",
    "radical_variants_unique = pd.concat([radical_variants_unique[0],radical_variants_unique[1]],axis=0).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merging traditional and simplified radicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>radical</th>\n",
       "      <th>variants</th>\n",
       "      <th>simplifiedradical</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>strokecount</th>\n",
       "      <th>char</th>\n",
       "      <th>ucn</th>\n",
       "      <th>Meaning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yi1</td>\n",
       "      <td>1</td>\n",
       "      <td>一</td>\n",
       "      <td>U+4E00</td>\n",
       "      <td>[one, a, an, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>丨</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gun3</td>\n",
       "      <td>1</td>\n",
       "      <td>丨</td>\n",
       "      <td>U+4E28</td>\n",
       "      <td>[number one, line]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>丿</td>\n",
       "      <td>乀 (fu2), 乁(yi2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pie3</td>\n",
       "      <td>1</td>\n",
       "      <td>丿</td>\n",
       "      <td>U+4E3F</td>\n",
       "      <td>[slash, line]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>乙</td>\n",
       "      <td>乚 (yin3), 乛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yi4</td>\n",
       "      <td>1</td>\n",
       "      <td>乙</td>\n",
       "      <td>U+4E59</td>\n",
       "      <td>[second, 2nd heavenly stem]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>亅</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jue2</td>\n",
       "      <td>1</td>\n",
       "      <td>亅</td>\n",
       "      <td>U+4E85</td>\n",
       "      <td>[hook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>210</td>\n",
       "      <td>齊</td>\n",
       "      <td>NaN</td>\n",
       "      <td>齐</td>\n",
       "      <td>qi2</td>\n",
       "      <td>14</td>\n",
       "      <td>齊</td>\n",
       "      <td>U+9F4A</td>\n",
       "      <td>[even, uniform, of equal length]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211</td>\n",
       "      <td>齒</td>\n",
       "      <td>NaN</td>\n",
       "      <td>齿</td>\n",
       "      <td>chi3</td>\n",
       "      <td>15</td>\n",
       "      <td>齒</td>\n",
       "      <td>U+9F52</td>\n",
       "      <td>[tooth, teeth, gears, cogs, age]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212</td>\n",
       "      <td>龍</td>\n",
       "      <td>NaN</td>\n",
       "      <td>龙</td>\n",
       "      <td>long2</td>\n",
       "      <td>16</td>\n",
       "      <td>龍</td>\n",
       "      <td>U+9F8D</td>\n",
       "      <td>[dragon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213</td>\n",
       "      <td>龜</td>\n",
       "      <td>NaN</td>\n",
       "      <td>龟</td>\n",
       "      <td>gui1</td>\n",
       "      <td>16</td>\n",
       "      <td>龜</td>\n",
       "      <td>U+9F9C</td>\n",
       "      <td>[turtle or tortoise, cuckold]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214</td>\n",
       "      <td>龠</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yue4</td>\n",
       "      <td>17</td>\n",
       "      <td>龠</td>\n",
       "      <td>U+9FA0</td>\n",
       "      <td>[flute, pipe, ancient measure]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number radical         variants simplifiedradical pinyin  strokecount  \\\n",
       "0         1       一              NaN               NaN    yi1            1   \n",
       "1         2       丨              NaN               NaN   gun3            1   \n",
       "2         4       丿  乀 (fu2), 乁(yi2)               NaN   pie3            1   \n",
       "3         5       乙      乚 (yin3), 乛               NaN    yi4            1   \n",
       "4         6       亅              NaN               NaN   jue2            1   \n",
       "..      ...     ...              ...               ...    ...          ...   \n",
       "209     210       齊              NaN                 齐    qi2           14   \n",
       "210     211       齒              NaN                 齿   chi3           15   \n",
       "211     212       龍              NaN                 龙  long2           16   \n",
       "212     213       龜              NaN                 龟   gui1           16   \n",
       "213     214       龠              NaN               NaN   yue4           17   \n",
       "\n",
       "    char     ucn                           Meaning  \n",
       "0      一  U+4E00               [one, a, an, alone]  \n",
       "1      丨  U+4E28                [number one, line]  \n",
       "2      丿  U+4E3F                     [slash, line]  \n",
       "3      乙  U+4E59       [second, 2nd heavenly stem]  \n",
       "4      亅  U+4E85                            [hook]  \n",
       "..   ...     ...                               ...  \n",
       "209    齊  U+9F4A  [even, uniform, of equal length]  \n",
       "210    齒  U+9F52  [tooth, teeth, gears, cogs, age]  \n",
       "211    龍  U+9F8D                          [dragon]  \n",
       "212    龜  U+9F9C     [turtle or tortoise, cuckold]  \n",
       "213    龠  U+9FA0    [flute, pipe, ancient measure]  \n",
       "\n",
       "[214 rows x 9 columns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_radicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radicals['simplifiedradical'].fillna(df_radicals['radical'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_radicals['simplifiedradical'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting instances where there is a traditional radical\n",
    "\n",
    "df_radicals['traditional'] = np.where(df_radicals['simplifiedradical'] != df_radicals['radical'],df_radicals['radical'],np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number', 'radical', 'variants', 'simplifiedradical', 'pinyin',\n",
       "       'strokecount', 'char', 'ucn', 'Meaning', 'traditional'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_radicals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>radical</th>\n",
       "      <th>variants</th>\n",
       "      <th>simplifiedradical</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>strokecount</th>\n",
       "      <th>char</th>\n",
       "      <th>ucn</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>traditional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>144</td>\n",
       "      <td>行</td>\n",
       "      <td>NaN</td>\n",
       "      <td>行</td>\n",
       "      <td>xing2</td>\n",
       "      <td>6</td>\n",
       "      <td>行</td>\n",
       "      <td>U+884C</td>\n",
       "      <td>[walk enclosure, go, walk, move, travel, circu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>卩</td>\n",
       "      <td>NaN</td>\n",
       "      <td>卩</td>\n",
       "      <td>jie2</td>\n",
       "      <td>2</td>\n",
       "      <td>卩</td>\n",
       "      <td>U+5369</td>\n",
       "      <td>[seal]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>162</td>\n",
       "      <td>辵</td>\n",
       "      <td>辶</td>\n",
       "      <td>辵</td>\n",
       "      <td>chuo4</td>\n",
       "      <td>7</td>\n",
       "      <td>辵</td>\n",
       "      <td>U+8FB5</td>\n",
       "      <td>[walk, walking]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number radical variants simplifiedradical pinyin  strokecount char  \\\n",
       "142     144       行      NaN                 行  xing2            6    行   \n",
       "25       26       卩      NaN                 卩   jie2            2    卩   \n",
       "161     162       辵        辶                 辵  chuo4            7    辵   \n",
       "\n",
       "        ucn                                            Meaning traditional  \n",
       "142  U+884C  [walk enclosure, go, walk, move, travel, circu...         NaN  \n",
       "25   U+5369                                             [seal]         NaN  \n",
       "161  U+8FB5                                    [walk, walking]         NaN  "
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_radicals.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radicals.drop(['simplifiedradical','char'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radicals.columns =['radical_number', 'radical', 'variants', 'pinyin', 'stroke_count', 'ucn',\n",
    "       'meaning', 'traditional']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radical_number</th>\n",
       "      <th>radical</th>\n",
       "      <th>variants</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>stroke_count</th>\n",
       "      <th>ucn</th>\n",
       "      <th>meaning</th>\n",
       "      <th>traditional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>卩</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jie2</td>\n",
       "      <td>2</td>\n",
       "      <td>U+5369</td>\n",
       "      <td>[seal]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    radical_number radical variants pinyin  stroke_count     ucn meaning  \\\n",
       "25              26       卩      NaN   jie2             2  U+5369  [seal]   \n",
       "\n",
       "   traditional  \n",
       "25         NaN  "
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_radicals.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_radicals['radical_index'] = df_radicals.index + 100_000\n",
    "df_radicals.to_sql('radicals',conn,if_exists='replace',index=df_radicals['radical_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM radicals_info': no such table: radicals_info",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:2018\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2017\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2018\u001b[0m     cur\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2019\u001b[0m     \u001b[39mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: radicals_info",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/jentlejames/Projects/Data/ccrsApp/backend/nb/extract_data.ipynb Cell 47\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jentlejames/Projects/Data/ccrsApp/backend/nb/extract_data.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_test_radicals \u001b[39m=\u001b[39m  pd\u001b[39m.\u001b[39;49mread_sql(\u001b[39m'\u001b[39;49m\u001b[39mSELECT * FROM radicals_info\u001b[39;49m\u001b[39m'\u001b[39;49m, conn, index_col\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mradical_index\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jentlejames/Projects/Data/ccrsApp/backend/nb/extract_data.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_test_radicals\u001b[39m.\u001b[39msample(\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:564\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    561\u001b[0m pandas_sql \u001b[39m=\u001b[39m pandasSQL_builder(con)\n\u001b[1;32m    563\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 564\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mread_query(\n\u001b[1;32m    565\u001b[0m         sql,\n\u001b[1;32m    566\u001b[0m         index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m    567\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    568\u001b[0m         coerce_float\u001b[39m=\u001b[39;49mcoerce_float,\n\u001b[1;32m    569\u001b[0m         parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m    570\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    571\u001b[0m     )\n\u001b[1;32m    573\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    574\u001b[0m     _is_table_name \u001b[39m=\u001b[39m pandas_sql\u001b[39m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:2078\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize, dtype)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_query\u001b[39m(\n\u001b[1;32m   2067\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   2068\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2074\u001b[0m     dtype: DtypeArg \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2075\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m   2077\u001b[0m     args \u001b[39m=\u001b[39m _convert_params(sql, params)\n\u001b[0;32m-> 2078\u001b[0m     cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m   2079\u001b[0m     columns \u001b[39m=\u001b[39m [col_desc[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m col_desc \u001b[39min\u001b[39;00m cursor\u001b[39m.\u001b[39mdescription]\n\u001b[1;32m   2081\u001b[0m     \u001b[39mif\u001b[39;00m chunksize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/sql.py:2030\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2027\u001b[0m     \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39minner_exc\u001b[39;00m\n\u001b[1;32m   2029\u001b[0m ex \u001b[39m=\u001b[39m DatabaseError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecution failed on sql \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00margs[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mexc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2030\u001b[0m \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM radicals_info': no such table: radicals_info"
     ]
    }
   ],
   "source": [
    "df_test_radicals =  pd.read_sql('SELECT * FROM radicals_info', conn, index_col='radical_index')\n",
    "df_test_radicals.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary Words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_cedict = pd.read_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traditional</th>\n",
       "      <th>simplified</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72029</th>\n",
       "      <td>生煎包</td>\n",
       "      <td>生煎包</td>\n",
       "      <td>sheng1 jian1 bao1</td>\n",
       "      <td>pan-fried dumpling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77405</th>\n",
       "      <td>磁重聯</td>\n",
       "      <td>磁重联</td>\n",
       "      <td>ci2 chong2 lian2</td>\n",
       "      <td>(physics) magnetic reconnection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42352</th>\n",
       "      <td>戈爾</td>\n",
       "      <td>戈尔</td>\n",
       "      <td>Ge1 er3</td>\n",
       "      <td>Gore (name)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      traditional simplified             pinyin  \\\n",
       "72029         生煎包        生煎包  sheng1 jian1 bao1   \n",
       "77405         磁重聯        磁重联   ci2 chong2 lian2   \n",
       "42352          戈爾         戈尔            Ge1 er3   \n",
       "\n",
       "                               english  \n",
       "72029               pan-fried dumpling  \n",
       "77405  (physics) magnetic reconnection  \n",
       "42352                      Gore (name)  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cedict = pd.read_csv(DATA_DIR/'extracted'/'ce_dict.csv')\n",
    "df_cedict.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cedict['cedict_index'] = df_cedict.index + 2_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120683"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cedict.to_sql('ce_dictionary',conn,if_exists='replace',index=df_cedict['cedict_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cedict =  pd.read_sql('SELECT * FROM ce_dictionary', conn, index_col='cedict_index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>traditional</th>\n",
       "      <th>simplified</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cedict_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2079479</th>\n",
       "      <td>穿堂風</td>\n",
       "      <td>穿堂风</td>\n",
       "      <td>chuan1 tang2 feng1</td>\n",
       "      <td>draft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115669</th>\n",
       "      <td>養</td>\n",
       "      <td>养</td>\n",
       "      <td>yang3</td>\n",
       "      <td>to raise (animals)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113853</th>\n",
       "      <td>面色</td>\n",
       "      <td>面色</td>\n",
       "      <td>mian4 se4</td>\n",
       "      <td>complexion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             traditional simplified              pinyin             english\n",
       "cedict_index                                                               \n",
       "2079479              穿堂風        穿堂风  chuan1 tang2 feng1               draft\n",
       "2115669                養          养               yang3  to raise (animals)\n",
       "2113853               面色         面色           mian4 se4          complexion"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_cedict.sample(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSK (used to add statistics and remove stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hsk = pd.read_csv(DATA_DIR/'HSK Standard Course 1-6-Table 1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Traditional</th>\n",
       "      <th>Simplified</th>\n",
       "      <th>English</th>\n",
       "      <th>HSK</th>\n",
       "      <th>HSK 5（二）词语搭配</th>\n",
       "      <th>Img</th>\n",
       "      <th>Txt</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>...</th>\n",
       "      <th>Alternative</th>\n",
       "      <th>Grammar Reference</th>\n",
       "      <th>Song Lyrics</th>\n",
       "      <th>Song YouTube</th>\n",
       "      <th>Song Pinyin</th>\n",
       "      <th>Song Translation</th>\n",
       "      <th>Example Pinyin</th>\n",
       "      <th>Length</th>\n",
       "      <th>Character Phrase</th>\n",
       "      <th>Instagram Image Created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>2159</td>\n",
       "      <td>油炸</td>\n",
       "      <td>油炸</td>\n",
       "      <td>to deep-fry</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>yóu zhá</td>\n",
       "      <td>油炸，就是 to deep-fry。</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yào jiādiǎn tǔdòuní háishi yóuzhá tǔdòu tiáo</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4622</th>\n",
       "      <td>4625</td>\n",
       "      <td>姿態</td>\n",
       "      <td>姿态</td>\n",
       "      <td>attitude, posture, stance</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>zī tài</td>\n",
       "      <td>姿态，就是态度，姿势。</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tā yǐ guànyòng de qiángyìng yáncí zuòchū wéikà...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>3332</td>\n",
       "      <td>精確</td>\n",
       "      <td>精确</td>\n",
       "      <td>accurate, precise</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>jīng què</td>\n",
       "      <td>精确，就是准确。</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tā jīngquè dì gù chū le zhòngliàng</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id Traditional Simplified                    English HSK  \\\n",
       "2157  2159          油炸         油炸                to deep-fry   5   \n",
       "4622  4625          姿態         姿态  attitude, posture, stance   6   \n",
       "3329  3332          精確         精确          accurate, precise   6   \n",
       "\n",
       "      HSK 5（二）词语搭配    Img    Txt    Pinyin         Explanation  ...  \\\n",
       "2157           NaN  False  False   yóu zhá  油炸，就是 to deep-fry。  ...   \n",
       "4622           NaN  False  False    zī tài         姿态，就是态度，姿势。  ...   \n",
       "3329           NaN  False  False  jīng què            精确，就是准确。  ...   \n",
       "\n",
       "     Alternative Grammar Reference Song Lyrics  Song YouTube Song Pinyin  \\\n",
       "2157         NaN               NaN         NaN           NaN         NaN   \n",
       "4622         NaN               NaN         NaN           NaN         NaN   \n",
       "3329         NaN               NaN         NaN           NaN         NaN   \n",
       "\n",
       "     Song Translation                                     Example Pinyin  \\\n",
       "2157              NaN       yào jiādiǎn tǔdòuní háishi yóuzhá tǔdòu tiáo   \n",
       "4622              NaN  tā yǐ guànyòng de qiángyìng yáncí zuòchū wéikà...   \n",
       "3329              NaN                 tā jīngquè dì gù chū le zhòngliàng   \n",
       "\n",
       "      Length Character Phrase Instagram Image Created  \n",
       "2157       2              NaN                     NaN  \n",
       "4622       2              NaN                     NaN  \n",
       "3329       2              NaN                     NaN  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hsk.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18896, 5)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences = pd.read_csv(DATA_DIR/'sentences.tsv',sep='\\t')\n",
    "df_sentences.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Characters</th>\n",
       "      <th>Pinyin</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>HSK average</th>\n",
       "      <th>Custom Ratio</th>\n",
       "      <th>sentence_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8696</th>\n",
       "      <td>我已经决定买一部脚踏车，不论贵不贵。</td>\n",
       "      <td>wǒ yǐjīng juédìng mǎi yī bù jiǎotàchē bùlùn gu...</td>\n",
       "      <td>I have decided to buy a bicycle, whether it is...</td>\n",
       "      <td>4.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>3008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15931</th>\n",
       "      <td>流星在空中画出了一道长长的弧线。</td>\n",
       "      <td>liúxīng zài kōngzhōng huà chū le yīdào cháng c...</td>\n",
       "      <td>The falling star described a long curve in the...</td>\n",
       "      <td>5.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>3015931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>我妹妹每天都吃天然食品，但是我不吃。</td>\n",
       "      <td>wǒ mèimei měitiān dōu chī tiānrán shípǐn dànsh...</td>\n",
       "      <td>My sister eats natural foods every day, but I ...</td>\n",
       "      <td>3.300</td>\n",
       "      <td>0.600</td>\n",
       "      <td>3002226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Characters                                             Pinyin  \\\n",
       "8696   我已经决定买一部脚踏车，不论贵不贵。  wǒ yǐjīng juédìng mǎi yī bù jiǎotàchē bùlùn gu...   \n",
       "15931    流星在空中画出了一道长长的弧线。  liúxīng zài kōngzhōng huà chū le yīdào cháng c...   \n",
       "2226   我妹妹每天都吃天然食品，但是我不吃。  wǒ mèimei měitiān dōu chī tiānrán shípǐn dànsh...   \n",
       "\n",
       "                                                 Meaning  HSK average  \\\n",
       "8696   I have decided to buy a bicycle, whether it is...        4.375   \n",
       "15931  The falling star described a long curve in the...        5.500   \n",
       "2226   My sister eats natural foods every day, but I ...        3.300   \n",
       "\n",
       "       Custom Ratio  sentence_index  \n",
       "8696          0.375         3008696  \n",
       "15931         0.250         3015931  \n",
       "2226          0.600         3002226  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences.columns = ['Characters', 'Pinyin', 'Meaning', 'HSK average',\n",
    "       'Custom Ratio']\n",
    "df_sentences['sentence_index'] = df_sentences.index + 3_000_000\n",
    "df_sentences.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping this row due to strange encoding behavior\n",
    "df_sentences.drop(15390,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18895"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences.to_sql('example_sentences',conn,if_exists='replace',index=df_sentences['sentence_index'])\n",
    "\n",
    "# Uncomment for debugging which rows aren't inserted\n",
    "\n",
    "#conn.close()\n",
    "#conn = sqlite3.connect('ccrs.db', isolation_level=None)\n",
    "#try:\n",
    "#    df_sentences.to_sql('example_sentences',conn,if_exists='replace',index=df_sentences['sentence_index'])\n",
    "#except Exception as e:\n",
    "#        print(f\"Error inserting row {df_links.loc[conn.total_changes]['sentence_index']} into database: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linking Tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link Dictionary to Example sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords =  stopwordsiso.stopwords(['zh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cedict_index</th>\n",
       "      <th>sentence_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67931</th>\n",
       "      <td>2091841</td>\n",
       "      <td>3005293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71834</th>\n",
       "      <td>2096471</td>\n",
       "      <td>3010622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71650</th>\n",
       "      <td>2096236</td>\n",
       "      <td>3002880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cedict_index  sentence_index\n",
       "67931       2091841         3005293\n",
       "71834       2096471         3010622\n",
       "71650       2096236         3002880"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a linking table\n",
    "df_sentences['words'] = df_sentences['Characters'].apply(lambda x: [w for w in jieba.lcut(x) if w not in stopwords])\n",
    "\n",
    "df_sentences_exploded = df_sentences.explode('words').reset_index(drop=True)\n",
    "\n",
    "df_links = pd.merge(df_cedict, df_sentences_exploded, left_on='simplified', right_on='words')\n",
    "df_links = df_links[['cedict_index', 'sentence_index']].drop_duplicates().reset_index(drop=True)\n",
    "df_links.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87699"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# created a linking table\n",
    "df_links.to_sql('cedict_sentences',conn,if_exists='replace',index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hanzi to Radicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radical_number</th>\n",
       "      <th>radical</th>\n",
       "      <th>variants</th>\n",
       "      <th>pinyin</th>\n",
       "      <th>stroke_count</th>\n",
       "      <th>ucn</th>\n",
       "      <th>meaning</th>\n",
       "      <th>traditional</th>\n",
       "      <th>radical_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>188</td>\n",
       "      <td>骨</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gu3</td>\n",
       "      <td>10</td>\n",
       "      <td>U+9AA8</td>\n",
       "      <td>[bone, skeleton, frame, framework]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>谷</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gu3</td>\n",
       "      <td>7</td>\n",
       "      <td>U+8C37</td>\n",
       "      <td>[valley, gorge, ravine]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>122</td>\n",
       "      <td>网</td>\n",
       "      <td>罒</td>\n",
       "      <td>wang3</td>\n",
       "      <td>6</td>\n",
       "      <td>U+7F51</td>\n",
       "      <td>[net, network]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     radical_number radical variants pinyin  stroke_count     ucn  \\\n",
       "187             188       骨      NaN    gu3            10  U+9AA8   \n",
       "149             150       谷      NaN    gu3             7  U+8C37   \n",
       "120             122       网        罒  wang3             6  U+7F51   \n",
       "\n",
       "                                meaning traditional  radical_index  \n",
       "187  [bone, skeleton, frame, framework]         NaN         100187  \n",
       "149             [valley, gorge, ravine]         NaN         100149  \n",
       "120                      [net, network]         NaN         100120  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EDA\n",
    "\n",
    "df_radicals.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of all radicals, varients and traditional \n",
    "unique_base_radicals =  pd.concat([df_radicals['radical'],df_radicals['traditional'],radical_variants_unique]).dropna().drop_duplicates(keep='first')\n",
    "\n",
    "#unique_radicals = pd.concat([df_radicals['radical'],df_radicals['variants'],df_radicals['rad']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decomp = pd.read_csv(DATA_DIR/'extracted'/'FlattenedDecompositionTable.csv',index_col=0,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8\n"
     ]
    }
   ],
   "source": [
    "import cchardet as chardet\n",
    "\n",
    "with open(DATA_DIR/'extracted'/'FlattenedDecompositionTable.csv','rb') as f :\n",
    "    result = chardet.detect(f.read())\n",
    "print(result['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# Checking to see if the components will eventually break down into characers\n",
    "main_component = df_decomp['Component']\n",
    "right_component =  df_decomp['RightComponent']\n",
    "left_component = df_decomp['LeftComponent']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(main_component.str.len() > 1).sum()\n",
    "right_component[right_component.str.len() > 1 ].str.replace(' ','')\n",
    "left_component[left_component.str.len() > 1 ].str.replace(' ','')\n",
    "\n",
    "# Filter rows with multiple radicals\n",
    "\n",
    "breakdown_right_components = right_component[right_component.str.len() > 1]\n",
    "breakdown_left_components = left_component[left_component.str.len() > 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7450980392156863"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breakdown_left_components.unique().shape[0] / breakdown_left_components.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85    爫\n",
       "dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_base_radicals[unique_base_radicals == '爫']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Component             伶\n",
       "Strokes               7\n",
       "CompositionType       吅\n",
       "LeftComponent         亻\n",
       "LeftStrokes           2\n",
       "RightComponent        令\n",
       "RightStrokes          5\n",
       "Signature          OOII\n",
       "Notes                 /\n",
       "Section               人\n",
       "Name: 310, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decomp.iloc[169]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_components =  pd.concat([main_component,right_component,left_component],axis=0).drop_duplicates(keep='first').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of the set of unique radicals that are in the set of unique components\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9549180327868853"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Percentage of the set of unique radicals that are in the set of unique components')\n",
    "unique_base_radicals.isin(unique_components).sum() / unique_base_radicals.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radicals that are not in the components_list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22       匸\n",
       "33       夊\n",
       "2       乀 \n",
       "3       乚 \n",
       "41       尣\n",
       "118      ⺮\n",
       "162     阝 \n",
       "182      飠\n",
       "2        乁\n",
       "3        乛\n",
       "45      巜 \n",
       "dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Radicals that are not in the components_list')\n",
    "unique_base_radicals[~unique_base_radicals.isin(unique_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1           丁\n",
       "3           七\n",
       "7           万\n",
       "8           丈\n",
       "9           三\n",
       "         ... \n",
       "19760       𠚍\n",
       "19762     木缶木\n",
       "20521       𠤏\n",
       "20750    口口田一\n",
       "20835       歯\n",
       "Length: 10448, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_components[~unique_components.isin(unique_base_radicals)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Decomposition\n",
    "\n",
    "Layer 1, layer 2, Layer 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the tree structure ready, it would be good to \n",
    "set it up in a few layers of decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component</th>\n",
       "      <th>Strokes</th>\n",
       "      <th>CompositionType</th>\n",
       "      <th>LeftComponent</th>\n",
       "      <th>LeftStrokes</th>\n",
       "      <th>RightComponent</th>\n",
       "      <th>RightStrokes</th>\n",
       "      <th>Signature</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>丁</td>\n",
       "      <td>2</td>\n",
       "      <td>吕</td>\n",
       "      <td>一</td>\n",
       "      <td>1</td>\n",
       "      <td>亅</td>\n",
       "      <td>1</td>\n",
       "      <td>MN</td>\n",
       "      <td>/</td>\n",
       "      <td>一</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Component  Strokes CompositionType LeftComponent  LeftStrokes  \\\n",
       "1         丁        2               吕             一            1   \n",
       "\n",
       "  RightComponent  RightStrokes Signature Notes Section  \n",
       "1              亅             1        MN     /       一  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decomp[df_decomp['Component'] == '丁']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ids_decomp = pd.read_csv(DATA_DIR/'extracted'/'idsDecomposition.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "queue = Queue()\n",
    "\n",
    "class HanziNode:\n",
    "    def __init__(self,val):\n",
    "        self.leftChild = None\n",
    "        self.rightChild = None\n",
    "        self.data = val\n",
    "\n",
    "\n",
    "    # Position Dict\n",
    "    # Order of traversal Inorder\n",
    "\n",
    "    # Print tree\n",
    "    def print_tree(self):\n",
    "        ret = []\n",
    "        ret.append(self.data)\n",
    "        if self.leftChild is not None:\n",
    "            queue.put(self.leftChild)\n",
    "        if self.rightChild is not None:\n",
    "            queue.put(self.rightChild)\n",
    "\n",
    "        #print (len(stack))\n",
    "        while queue.empty() is False:\n",
    "            ret = ret + queue.get().printTree() \n",
    "        return ret\n",
    "    \n",
    "    def preorder_traversal(self, root):\n",
    "        ret = []\n",
    "        if root:\n",
    "            ret.append(root.data)\n",
    "            ret = ret + self.preorderTraversal(root.leftChild)\n",
    "            ret = ret + self.preorderTraversal(root.rightChild)\n",
    "        return ret\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.leftChild is None and self.rightChild is None\n",
    "\n",
    "    def is_radical(self,radicals_col):\n",
    "        # Checks if the node is a radical\n",
    "        return radicals_col.str.contains(self.data).sum() != False\n",
    "    \n",
    "    def get_sub_components(self,df):\n",
    "        return df[df['Component'] == self.data]\n",
    "\n",
    "    def populate_tree(self, df_components):\n",
    "        components_df_row = self.get_sub_components(df_components)\n",
    "\n",
    "        if  components_df_row is not None or not self.is_radical(self.data):\n",
    "            leftComponent =  components_df_row['LeftComponent'].iloc[0]\n",
    "            rightComponent = components_df_row['RightComponent'].iloc[0]\n",
    "            #print(leftComponent)\n",
    "            #print(rightComponent)\n",
    "\n",
    "            if leftComponent is not None:\n",
    "                self.leftChild = HanziNode(leftComponent)\n",
    "            else:\n",
    "                self.leftChild = None\n",
    "                \n",
    "            if rightComponent is not None:\n",
    "                self.rightChild = HanziNode(rightComponent)\n",
    "            else:\n",
    "                self.rightChild = None\n",
    "                #self.rightChild.populate_tree(components_df_row) \n",
    "\n",
    "    def get_all_leaves(self):\n",
    "        if self.leftChild is None and self.rightChild is None:\n",
    "            return [self]\n",
    "        else:\n",
    "            leaves = []\n",
    "            if self.leftChild is not None:\n",
    "                leaves += self.leftChild.get_all_leaves()\n",
    "            if self.rightChild is not None:\n",
    "                leaves += self.rightChild.get_all_leaves()\n",
    "            return leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hanziDecompTreeDict = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radicalList = list(unique_base_radicals)\n",
    "for index,row in df_hanzi.iterrows():\n",
    "    hanzi = row['hanzi']\n",
    "    HanziRoot = HanziNode(hanzi)\n",
    "    hanziDecompTreeDict[index] = HanziRoot\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noDataOnCharacterList  = []\n",
    "\n",
    "for index, node in hanziDecompTreeDict.items():\n",
    "\n",
    "    try:\n",
    "        node.populate_tree(df_decomp)\n",
    "    except:\n",
    "        noDataOnCharacterList.append(index)\n",
    "\n",
    "\n",
    "for i in noDataOnCharacterList:\n",
    "    hanziDecompTreeDict[i].rightChild = None\n",
    "    hanziDecompTreeDict[i].leftChild = None "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noSecondLayerList = []\n",
    "\n",
    "for index, node in hanziDecompTreeDict.items():\n",
    "    try:\n",
    "        node.rightChild.populate_tree(df_decomp)\n",
    "        node.leftChild.populate_tree(df_decomp)\n",
    "    except:\n",
    "        noSecondLayerList.append(index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2\n",
    "\n",
    "for index, node in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noThirdLayerList = []\n",
    "\n",
    "for index, node in hanziDecompTreeDict.items():     \n",
    "    try:\n",
    "        node.rightChild.leftChild.populate_tree(df_decomp)\n",
    "        node.leftChild.leftChild.populate_tree(df_decomp)\n",
    "        node.rightChild.rightChild.populate_tree(df_decomp)\n",
    "        node.rightChild.leftChild.populate_tree(df_decomp)\n",
    "    except:\n",
    "        noThirdLayerList.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input to Pandas Series object\n",
    "#def check_for_rare_characters(col):\n",
    "\n",
    "char_series = df_decomp['LeftComponent']\n",
    "char_series = char_series.dropna().str[0]\n",
    "# Convert each character to its hexadecimal representation\n",
    "char_series = char_series.apply( lambda x: ord(x))\n",
    "\n",
    "# Define Unicode sets\n",
    "common_set = set(range(0x4E00, 0xA000))  # \n",
    "extension_a_set = set(range(0x3400, 0x4E00))  #  Extension A\n",
    "extension_b_set = set(range(0x20000, 0x2A6E0))  #  Extension B\n",
    "extension_c_set = set(range(0x2A700, 0x2B740))  #  Extension C\n",
    "extension_d_set = set(range(0x2B740, 0x2B820))  #  Extension D\n",
    "extension_e_set = set(range(0x2B820, 0x2CEB0))  #  Extension E\n",
    "extension_f_set = set(range(0x2CEB0, 0x2EC00))  #  Extension F\n",
    "extension_g_set = set(range(0x30000, 0x31350))  #  Extension G\n",
    "extension_h_set = set(range(0x31350, 0x32400))  #  Extension H\n",
    "\n",
    "# Convert Unicode code points to strings and create pandas Series\n",
    "\n",
    "extension_a_chars = pd.Series([chr(cp) for cp in extension_a_set])\n",
    "extension_b_chars = pd.Series([chr(cp) for cp in extension_b_set])\n",
    "extension_c_chars = pd.Series([chr(cp) for cp in extension_c_set])\n",
    "extension_d_chars = pd.Series([chr(cp) for cp in extension_d_set])\n",
    "extension_e_chars = pd.Series([chr(cp) for cp in extension_e_set])\n",
    "extension_f_chars = pd.Series([chr(cp) for cp in extension_f_set])\n",
    "extension_g_chars = pd.Series([chr(cp) for cp in extension_g_set])\n",
    "extension_h_chars = pd.Series([chr(cp) for cp in extension_h_set])\n",
    "\n",
    "\n",
    "# Define vectorized functions for each Unicode set\n",
    "common_mask = char_series.isin(common_set)\n",
    "extension_a_mask = char_series.isin(extension_a_chars)\n",
    "extension_b_mask = char_series.isin(extension_b_chars)\n",
    "extension_c_mask = char_series.isin(extension_c_chars)\n",
    "extension_d_mask = char_series.isin(extension_d_chars)\n",
    "extension_e_mask = char_series.isin(extension_e_chars)\n",
    "extension_f_mask = char_series.isin(extension_f_chars)\n",
    "extension_g_mask = char_series.isin(extension_g_chars)\n",
    "extension_h_mask = char_series.isin(extension_h_chars)\n",
    "\n",
    "# Create new column that specifies which Unicode set each character belongs to\n",
    "# Create Series of character sets\n",
    "char_set_series = pd.Series('', index=char_series.index)\n",
    "char_set_series[common_mask] = ''\n",
    "char_set_series[extension_a_mask] = 'A'\n",
    "char_set_series[extension_b_mask] = 'B'\n",
    "char_set_series[extension_c_mask] = 'C'\n",
    "char_set_series[extension_d_mask] = 'D'\n",
    "char_set_series[extension_e_mask] = 'E'\n",
    "char_set_series[extension_f_mask] = 'F'\n",
    "char_set_series[extension_g_mask] = 'G'\n",
    "char_set_series[extension_h_mask] = 'H'\n",
    "\n",
    "#df['char_set'] = char_set_series\n",
    "\n",
    "#return char_series\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 1\n",
    "\n",
    "level_one_right_child_dict = {}\n",
    "level_two_right_left_descendant = {}\n",
    "level_two_right_right_descendant = {}\n",
    "\n",
    "level_one_left_child_dict = {}\n",
    "level_two_left_left_descendant = {}\n",
    "level_two_left_right_descendant = {}\n",
    "\n",
    "for idx, tree in hanziDecompTreeDict.items():\n",
    "    if type(idx) != int:\n",
    "        print(idx,tree)\n",
    "    if tree.rightChild is not None:\n",
    "        level_one_right_child_dict[idx] = tree.rightChild.data\n",
    "\n",
    "        if tree.rightChild.leftChild is not None:\n",
    "            level_two_right_left_descendant[idx] = tree.rightChild.leftChild.data \n",
    "        if tree.rightChild.rightChild is not None:\n",
    "            level_two_right_right_descendant[idx] = tree.rightChild.rightChild.data\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "    if tree.leftChild is not None:\n",
    "        level_one_left_child_dict[idx] = tree.leftChild.data\n",
    "        if tree.leftChild.leftChild is not None:\n",
    "            level_two_left_left_descendant[idx] = tree.leftChild.leftChild.data \n",
    "        if tree.leftChild.rightChild is not None:\n",
    "            level_two_left_right_descendant[idx] = tree.leftChild.rightChild.data\n",
    "        else:\n",
    "            continue\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_tree(node):\n",
    "    \"\"\"\n",
    "    Recursively traverses the tree and returns a dictionary of nodes.\n",
    "    \"\"\"\n",
    "    if node is None:\n",
    "        return {}\n",
    "\n",
    "    left_descendant = traverse_tree(node.leftChild)\n",
    "    right_descendant = traverse_tree(node.rightChild)\n",
    "\n",
    "    node_dict = {\n",
    "        'data': node.data,\n",
    "        'left_child': left_descendant,\n",
    "        'right_child': right_descendant\n",
    "    }\n",
    "\n",
    "    return node_dict\n",
    "\n",
    "hanzi_idx = 1001\n",
    "# Example usage:\n",
    "tree_dict = traverse_tree(hanziDecompTreeDict[hanzi_idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_tree(tree, hanzi_idx):\n",
    "    result = []\n",
    "    counter = 0\n",
    "\n",
    "    def flatten_node(node, hanzi_idx):\n",
    "        nonlocal counter\n",
    "        counter += 1\n",
    "        \n",
    "        if counter > 1:\n",
    "            result.append((hanzi_idx, node['data'], counter - 1))\n",
    "\n",
    "        if node['left_child']:\n",
    "            flatten_node(node['left_child'], hanzi_idx )\n",
    "        if node['right_child']:\n",
    "            flatten_node(node['right_child'], hanzi_idx)\n",
    "\n",
    "    flatten_node(tree, hanzi_idx)\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_component_list = []\n",
    "\n",
    "for hanzi_idx, RootNode in hanziDecompTreeDict.items():\n",
    "    tree_dict = traverse_tree(RootNode)\n",
    "    flat_rows = flatten_tree(tree_dict,hanzi_idx)\n",
    "    flat_component_list = flat_component_list + flat_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hanzi_components = pd.DataFrame(flat_component_list, columns=['hanzi_index','component','position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out * inside of the dataset\n",
    "df_hanzi_components  = df_hanzi_components[df_hanzi_components['component'] != '*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39072"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hanzi_components.to_sql('hanzi_components',conn,if_exists='replace')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weibo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chengyu (Idioms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChineseAutomation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
